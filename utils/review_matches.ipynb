{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\OneDrive\\Escritorio\\SportsAnalyticsCourse\\OptaForum\\OptaChallenge_Clustering_Player_Styles\\data\\tracking_set_0\n",
      "c:\\Users\\Gabriel\\OneDrive\\Escritorio\\SportsAnalyticsCourse\\OptaForum\\OptaChallenge_Clustering_Player_Styles\\data\\first_10_events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\513356439.py:42: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>eventId</th>\n",
       "      <th>event_type_id</th>\n",
       "      <th>current_phase</th>\n",
       "      <th>period_minute</th>\n",
       "      <th>period_second</th>\n",
       "      <th>contestantId</th>\n",
       "      <th>outcome</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>lastModified</th>\n",
       "      <th>qualifier</th>\n",
       "      <th>playerId</th>\n",
       "      <th>lineBreakingPass.linesBroken.value</th>\n",
       "      <th>passOption.player</th>\n",
       "      <th>passTarget.player</th>\n",
       "      <th>xThreat.applied</th>\n",
       "      <th>lineBreakingPass.lastLineBroken.value</th>\n",
       "      <th>pressure.pressureReceived.value</th>\n",
       "      <th>pressure.player</th>\n",
       "      <th>xThreat.removed</th>\n",
       "      <th>keyPass</th>\n",
       "      <th>assist</th>\n",
       "      <th>timeelapsed</th>\n",
       "      <th>event_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2423549045</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3c3jcs7vc1t6vz5lev162jyv7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-22T03:17:52Z</td>\n",
       "      <td>[{'id': 3586084711, 'qualifierId': 127, 'value...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Period start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2423549041</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bx0cdmzr2gwr70ez72dorx82p</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-05-21T18:59:34Z</td>\n",
       "      <td>[{'id': 3586084701, 'qualifierId': 127, 'value...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Period start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2423549063</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bx0cdmzr2gwr70ez72dorx82p</td>\n",
       "      <td>1</td>\n",
       "      <td>49.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2022-05-22T03:34:41Z</td>\n",
       "      <td>[{'id': 3586084825, 'qualifierId': 56, 'value'...</td>\n",
       "      <td>6u2ob6fv950r1qve8uejkq2uh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2423549097</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>bx0cdmzr2gwr70ez72dorx82p</td>\n",
       "      <td>1</td>\n",
       "      <td>31.5</td>\n",
       "      <td>57.2</td>\n",
       "      <td>2022-05-22T06:37:07Z</td>\n",
       "      <td>[{'id': 3586085043, 'qualifierId': 213, 'value...</td>\n",
       "      <td>azuc3tma44xyrbgf5y279o1xx</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'playerId': 'e3kdoxu1kwn2w3wwi1rqhvr9x', 'sh...</td>\n",
       "      <td>[{'playerId': '7sep6mx2s67mh5fr3raxu7aei', 'sh...</td>\n",
       "      <td>0.0029771626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.84</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2423549113</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>bx0cdmzr2gwr70ez72dorx82p</td>\n",
       "      <td>1</td>\n",
       "      <td>49.2</td>\n",
       "      <td>95.4</td>\n",
       "      <td>2022-05-22T06:37:06Z</td>\n",
       "      <td>[{'id': 3586085129, 'qualifierId': 212, 'value...</td>\n",
       "      <td>7sep6mx2s67mh5fr3raxu7aei</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'playerId': '5qgc6zjc38a5xjl35gs7h3vu1', 'sh...</td>\n",
       "      <td>[{'playerId': 'e3kdoxu1kwn2w3wwi1rqhvr9x', 'sh...</td>\n",
       "      <td>0.0309752524</td>\n",
       "      <td>secondToLast</td>\n",
       "      <td>high</td>\n",
       "      <td>[{'playerId': 'e6ok0deqkoe80184iu509gzu2', 'sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.88</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  eventId  event_type_id  current_phase  period_minute  \\\n",
       "2  2423549045        2             32              1              0   \n",
       "3  2423549041        2             32              1              0   \n",
       "4  2423549063        3              1              1              0   \n",
       "5  2423549097        4              1              1              0   \n",
       "6  2423549113        5              1              1              0   \n",
       "\n",
       "   period_second               contestantId  outcome     x     y  \\\n",
       "2              0  3c3jcs7vc1t6vz5lev162jyv7        1   0.0   0.0   \n",
       "3              0  bx0cdmzr2gwr70ez72dorx82p        1   0.0   0.0   \n",
       "4              0  bx0cdmzr2gwr70ez72dorx82p        1  49.9  50.0   \n",
       "5              2  bx0cdmzr2gwr70ez72dorx82p        1  31.5  57.2   \n",
       "6              7  bx0cdmzr2gwr70ez72dorx82p        1  49.2  95.4   \n",
       "\n",
       "           lastModified                                          qualifier  \\\n",
       "2  2022-05-22T03:17:52Z  [{'id': 3586084711, 'qualifierId': 127, 'value...   \n",
       "3  2022-05-21T18:59:34Z  [{'id': 3586084701, 'qualifierId': 127, 'value...   \n",
       "4  2022-05-22T03:34:41Z  [{'id': 3586084825, 'qualifierId': 56, 'value'...   \n",
       "5  2022-05-22T06:37:07Z  [{'id': 3586085043, 'qualifierId': 213, 'value...   \n",
       "6  2022-05-22T06:37:06Z  [{'id': 3586085129, 'qualifierId': 212, 'value...   \n",
       "\n",
       "                    playerId lineBreakingPass.linesBroken.value  \\\n",
       "2                        NaN                                NaN   \n",
       "3                        NaN                                NaN   \n",
       "4  6u2ob6fv950r1qve8uejkq2uh                                NaN   \n",
       "5  azuc3tma44xyrbgf5y279o1xx                                  0   \n",
       "6  7sep6mx2s67mh5fr3raxu7aei                                  1   \n",
       "\n",
       "                                   passOption.player  \\\n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5  [{'playerId': 'e3kdoxu1kwn2w3wwi1rqhvr9x', 'sh...   \n",
       "6  [{'playerId': '5qgc6zjc38a5xjl35gs7h3vu1', 'sh...   \n",
       "\n",
       "                                   passTarget.player xThreat.applied  \\\n",
       "2                                                NaN             NaN   \n",
       "3                                                NaN             NaN   \n",
       "4                                                NaN             NaN   \n",
       "5  [{'playerId': '7sep6mx2s67mh5fr3raxu7aei', 'sh...    0.0029771626   \n",
       "6  [{'playerId': 'e3kdoxu1kwn2w3wwi1rqhvr9x', 'sh...    0.0309752524   \n",
       "\n",
       "  lineBreakingPass.lastLineBroken.value pressure.pressureReceived.value  \\\n",
       "2                                   NaN                             NaN   \n",
       "3                                   NaN                             NaN   \n",
       "4                                   NaN                             NaN   \n",
       "5                                   NaN                             NaN   \n",
       "6                          secondToLast                            high   \n",
       "\n",
       "                                     pressure.player xThreat.removed  keyPass  \\\n",
       "2                                                NaN             NaN      NaN   \n",
       "3                                                NaN             NaN      NaN   \n",
       "4                                                NaN             NaN      NaN   \n",
       "5                                                NaN             NaN      NaN   \n",
       "6  [{'playerId': 'e6ok0deqkoe80184iu509gzu2', 'sh...             NaN      NaN   \n",
       "\n",
       "   assist  timeelapsed event_description  \n",
       "2     NaN         0.00      Period start  \n",
       "3     NaN         0.00      Period start  \n",
       "4     NaN         0.04              Pass  \n",
       "5     NaN         2.84              Pass  \n",
       "6     NaN         7.88              Pass  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Period start' 'Pass' 'Take On' 'Challenge' 'Blocked Pass'\n",
      " 'Ball recovery' 'Attempted Tackle' 'Out' 'Ball touch' '50/50'\n",
      " 'Dispossessed' 'Tackle' 'Corner Awarded' 'Clearance' 'Offside Pass'\n",
      " 'Offside provoked' 'Foul' 'Aerial' 'Keeper pick-up' 'Deleted event'\n",
      " 'Interception' 'Error' 'Goal' 'Attempt Saved' 'Save' 'Miss' 'Claim'\n",
      " 'Card' 'Start delay' 'End delay' 'Referee Drop Ball' nan 'End'\n",
      " 'Player Off' 'Player on' 'Formation change' 'Keeper Sweeper'\n",
      " 'Shield ball opp']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qualifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2423549045</td>\n",
       "      <td>{'id': 3586084711, 'qualifierId': 127, 'value'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2423549041</td>\n",
       "      <td>{'id': 3586084701, 'qualifierId': 127, 'value'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2423549063</td>\n",
       "      <td>{'id': 3586084825, 'qualifierId': 56, 'value':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2423549063</td>\n",
       "      <td>{'id': 3586084833, 'qualifierId': 213, 'value'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2423549063</td>\n",
       "      <td>{'id': 3586084827, 'qualifierId': 140, 'value'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          qualifier\n",
       "2  2423549045  {'id': 3586084711, 'qualifierId': 127, 'value'...\n",
       "3  2423549041  {'id': 3586084701, 'qualifierId': 127, 'value'...\n",
       "4  2423549063  {'id': 3586084825, 'qualifierId': 56, 'value':...\n",
       "4  2423549063  {'id': 3586084833, 'qualifierId': 213, 'value'...\n",
       "4  2423549063  {'id': 3586084827, 'qualifierId': 140, 'value'..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "(9430, 2)\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qualifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2423549045</td>\n",
       "      <td>{'id': 3586084711, 'qualifierId': 127, 'value'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2423549041</td>\n",
       "      <td>{'id': 3586084701, 'qualifierId': 127, 'value'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2423549063</td>\n",
       "      <td>{'id': 3586084825, 'qualifierId': 56, 'value':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2423549063</td>\n",
       "      <td>{'id': 3586084833, 'qualifierId': 213, 'value'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2423549063</td>\n",
       "      <td>{'id': 3586084827, 'qualifierId': 140, 'value'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                          qualifier\n",
       "0  2423549045  {'id': 3586084711, 'qualifierId': 127, 'value'...\n",
       "1  2423549041  {'id': 3586084701, 'qualifierId': 127, 'value'...\n",
       "2  2423549063  {'id': 3586084825, 'qualifierId': 56, 'value':...\n",
       "3  2423549063  {'id': 3586084833, 'qualifierId': 213, 'value'...\n",
       "4  2423549063  {'id': 3586084827, 'qualifierId': 140, 'value'..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "(9430, 3)\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qualifierId</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3586084711</td>\n",
       "      <td>127</td>\n",
       "      <td>Right to Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3586084701</td>\n",
       "      <td>127</td>\n",
       "      <td>Left to Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3586084825</td>\n",
       "      <td>56</td>\n",
       "      <td>Back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3586084833</td>\n",
       "      <td>213</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3586084827</td>\n",
       "      <td>140</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  qualifierId          value\n",
       "0  3586084711          127  Right to Left\n",
       "1  3586084701          127  Left to Right\n",
       "2  3586084825           56           Back\n",
       "3  3586084833          213            2.7\n",
       "4  3586084827          140           28.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qualifierId</th>\n",
       "      <th>value</th>\n",
       "      <th>event_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3586084711</td>\n",
       "      <td>127</td>\n",
       "      <td>Right to Left</td>\n",
       "      <td>2423549045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3586084701</td>\n",
       "      <td>127</td>\n",
       "      <td>Left to Right</td>\n",
       "      <td>2423549041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3586084825</td>\n",
       "      <td>56</td>\n",
       "      <td>Back</td>\n",
       "      <td>2423549063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3586084833</td>\n",
       "      <td>213</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2423549063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3586084827</td>\n",
       "      <td>140</td>\n",
       "      <td>28.5</td>\n",
       "      <td>2423549063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  qualifierId          value    event_id\n",
       "0  3586084711          127  Right to Left  2423549045\n",
       "1  3586084701          127  Left to Right  2423549041\n",
       "2  3586084825           56           Back  2423549063\n",
       "3  3586084833          213            2.7  2423549063\n",
       "4  3586084827          140           28.5  2423549063"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qualifierId</th>\n",
       "      <th>value</th>\n",
       "      <th>event_id</th>\n",
       "      <th>qualifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3586084711</td>\n",
       "      <td>127</td>\n",
       "      <td>Right to Left</td>\n",
       "      <td>2423549045</td>\n",
       "      <td>Direction of Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3586084701</td>\n",
       "      <td>127</td>\n",
       "      <td>Left to Right</td>\n",
       "      <td>2423549041</td>\n",
       "      <td>Direction of Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3586084825</td>\n",
       "      <td>56</td>\n",
       "      <td>Back</td>\n",
       "      <td>2423549063</td>\n",
       "      <td>Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3586084833</td>\n",
       "      <td>213</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2423549063</td>\n",
       "      <td>Angle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3586084827</td>\n",
       "      <td>140</td>\n",
       "      <td>28.5</td>\n",
       "      <td>2423549063</td>\n",
       "      <td>Pass End X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  qualifierId          value    event_id          qualifier\n",
       "0  3586084711          127  Right to Left  2423549045  Direction of Play\n",
       "1  3586084701          127  Left to Right  2423549041  Direction of Play\n",
       "2  3586084825           56           Back  2423549063               Zone\n",
       "3  3586084833          213            2.7  2423549063              Angle\n",
       "4  3586084827          140           28.5  2423549063         Pass End X"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tracking data\n",
    "current_directory = os.getcwd()\n",
    "path_tracking = os.path.join(os.path.join(os.path.dirname(current_directory),'data'),\"tracking_set_0\")\n",
    "print(path_tracking)\n",
    "game_id = 1\n",
    "\n",
    "df_tracking = pd.read_parquet(f'{path_tracking}/{game_id}_tracking.parquet')\n",
    "\n",
    "#           ------------------------------------------------------------        \n",
    "\n",
    "# load events names\n",
    "path_event_csv = os.path.join(os.path.dirname(current_directory),'data')\n",
    "df_event_names = pd.read_csv(os.path.join(path_event_csv,'event_names.csv'))\n",
    "dict_event_names = df_event_names.set_index('event_type_id').to_dict()['event_description']\n",
    "\n",
    "# load event data\n",
    "def load_event_data(file_name, base_path):\n",
    "    # read in event file\n",
    "    with open(f'{base_path}/{file_name}') as f:\n",
    "        data=json.loads(f.read())\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    # transform data into pandas dataframe\n",
    "    df_events = pd.json_normalize(data['liveData']['event'])\n",
    "    \n",
    "    # preprocess event data and keep relevant information only\n",
    "\n",
    "    # add timeelapsed to each event\n",
    "    df_events['timestamp'] = pd.to_datetime(df_events.timeStamp).apply(lambda x: x.timestamp())\n",
    "\n",
    "    df_events = df_events.query('periodId in [1,2]')\n",
    "\n",
    "    def add_timeelapsed_to_events(df):\n",
    "        start_time = df.query('typeId==32')['timestamp'].iloc[0]\n",
    "        df['timestamp_new'] = np.int64((df['timestamp'] - start_time)*1000)\n",
    "\n",
    "        df['timeelapsed'] = df['timestamp_new'].apply(lambda x: (40 * round(x/40))/1000)\n",
    "\n",
    "        return df\n",
    "\n",
    "    df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n",
    "\n",
    "    df_events = df_events.drop(columns=['timeStamp','timestamp','timestamp_new'])\n",
    "    \n",
    "    # rename some columns\n",
    "    df_events = df_events.rename(columns=\n",
    "        {\n",
    "            'periodId':'current_phase',\n",
    "            'typeId':'event_type_id',\n",
    "            'timeMin':'period_minute',\n",
    "            'timeSec':'period_second'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return df_events\n",
    "\n",
    "path_events = os.path.join(os.path.join(os.path.dirname(current_directory),'data'),\"first_10_events\")\n",
    "print(path_events)\n",
    "\n",
    "event_file = f'{game_id}.json'\n",
    "\n",
    "df_events = load_event_data(\n",
    "    base_path=path_events,\n",
    "    file_name=event_file\n",
    ")\n",
    "\n",
    "# add event descriptions\n",
    "df_events['event_description'] = df_events['event_type_id'].map(dict_event_names)\n",
    "\n",
    "# make a copy of it for later usage\n",
    "events_all = df_events.copy()\n",
    "\n",
    "display(df_events.head())\n",
    "print(df_events['event_description'].unique())\n",
    "\n",
    "\n",
    "#           ------------------------------------------------------------        \n",
    "\n",
    "\n",
    "# read in qualifier list\n",
    "path_data = os.path.join(os.path.dirname(current_directory),'data')\n",
    "qualifier_names = pd.read_csv(os.path.join(path_data,\"qualifier_names.csv\"))\n",
    "\n",
    "# explode coverts each element in each list to a separate row\n",
    "cols = ['id', 'qualifier']\n",
    "qualifiers = events_all[cols].explode('qualifier')\n",
    "display(qualifiers.head())\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "qualifiers = qualifiers[qualifiers.qualifier.notna()].reset_index(drop=True)\n",
    "print(qualifiers.shape)\n",
    "print(\"------------\")\n",
    "display(qualifiers.head())\n",
    "print(\"------------\")\n",
    "\n",
    "# save corresponding event ids for each qualifier\n",
    "event_ids = qualifiers.id.tolist()\n",
    "\n",
    "qualifiers = pd.json_normalize(qualifiers[qualifiers.qualifier.notna()]['qualifier'])\n",
    "print(qualifiers.shape)\n",
    "print(\"------------\")\n",
    "display(qualifiers.head())\n",
    "print(\"------------\")\n",
    "\n",
    "qualifiers['event_id'] = event_ids\n",
    "display(qualifiers.head())\n",
    "print(\"------------\")\n",
    "qualifiers = qualifiers.merge(qualifier_names, how='left', on='qualifierId')\n",
    "display(qualifiers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3c3jcs7vc1t6vz5lev162jyv7', 'bx0cdmzr2gwr70ez72dorx82p'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events['contestantId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3c3jcs7vc1t6vz5lev162jyv7' 'bx0cdmzr2gwr70ez72dorx82p']\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['121le8unjfzug3iu9pgkqa1c7' '98dr7jscv8adc8zgi2u403oij']\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2b3mar72yy8d6uvat1ka6tn3r' '4t4hod56fsj7utpjdor8so5q6']\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bx0cdmzr2gwr70ez72dorx82p' '4t4hod56fsj7utpjdor8so5q6']\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be2k34rut1lz79jxenabttqlc' '3xedluek08t2ka7oypwuullcn']\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['27xvwccz8kpmqsefjv2b2sc0o' '2b3mar72yy8d6uvat1ka6tn3r']\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3c3jcs7vc1t6vz5lev162jyv7' '27xvwccz8kpmqsefjv2b2sc0o']\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['70nn27vgkt6l48lvv5e66q7ww' '27xvwccz8kpmqsefjv2b2sc0o']\n",
      "------------\n",
      "['4t4hod56fsj7utpjdor8so5q6' '2sc9xfhu6tbru9hhlhr4a89zn']\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_5192\\1450538298.py:45: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\Gabriel\\\\OneDrive\\\\Escritorio\\\\SportsAnalyticsCourse\\\\OptaForum\\\\OptaChallenge_Clustering_Player_Styles\\\\data\\\\tracking_set_0/10_tracking.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m path_tracking \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(current_directory),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtracking_set_0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#print(path_tracking)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m df_tracking \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_tracking\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgame_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_tracking.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#           ------------------------------------------------------------        \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# load events names\u001b[39;00m\n\u001b[0;32m     15\u001b[0m path_event_csv \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(current_directory),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;124;03mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03mDataFrame\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    501\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mread(\n\u001b[0;32m    504\u001b[0m     path,\n\u001b[0;32m    505\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    506\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    507\u001b[0m     use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    509\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:244\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    242\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    245\u001b[0m     path,\n\u001b[0;32m    246\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    247\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    248\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    249\u001b[0m )\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    252\u001b[0m         path_or_handle, columns\u001b[38;5;241m=\u001b[39mcolumns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    253\u001b[0m     )\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\Lib\\site-packages\\pandas\\io\\parquet.py:102\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[1;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[0;32m     92\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     handles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m    103\u001b[0m         path_or_handle, mode, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m    104\u001b[0m     )\n\u001b[0;32m    105\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Gabriel\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\Gabriel\\\\OneDrive\\\\Escritorio\\\\SportsAnalyticsCourse\\\\OptaForum\\\\OptaChallenge_Clustering_Player_Styles\\\\data\\\\tracking_set_0/10_tracking.parquet'"
     ]
    }
   ],
   "source": [
    "games = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for game_id in games:\n",
    "\n",
    "    # load tracking data\n",
    "    current_directory = os.getcwd()\n",
    "    path_tracking = os.path.join(os.path.join(os.path.dirname(current_directory),'data'),\"tracking_set_0\")\n",
    "    #print(path_tracking)\n",
    "\n",
    "    df_tracking = pd.read_parquet(f'{path_tracking}/{game_id}_tracking.parquet')\n",
    "\n",
    "    #           ------------------------------------------------------------        \n",
    "\n",
    "    # load events names\n",
    "    path_event_csv = os.path.join(os.path.dirname(current_directory),'data')\n",
    "    df_event_names = pd.read_csv(os.path.join(path_event_csv,'event_names.csv'))\n",
    "    dict_event_names = df_event_names.set_index('event_type_id').to_dict()['event_description']\n",
    "\n",
    "    # load event data\n",
    "    def load_event_data(file_name, base_path):\n",
    "        # read in event file\n",
    "        with open(f'{base_path}/{file_name}') as f:\n",
    "            data=json.loads(f.read())\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        # transform data into pandas dataframe\n",
    "        df_events = pd.json_normalize(data['liveData']['event'])\n",
    "        \n",
    "        # preprocess event data and keep relevant information only\n",
    "\n",
    "        # add timeelapsed to each event\n",
    "        df_events['timestamp'] = pd.to_datetime(df_events.timeStamp).apply(lambda x: x.timestamp())\n",
    "\n",
    "        df_events = df_events.query('periodId in [1,2]')\n",
    "\n",
    "        def add_timeelapsed_to_events(df):\n",
    "            start_time = df.query('typeId==32')['timestamp'].iloc[0]\n",
    "            df['timestamp_new'] = np.int64((df['timestamp'] - start_time)*1000)\n",
    "\n",
    "            df['timeelapsed'] = df['timestamp_new'].apply(lambda x: (40 * round(x/40))/1000)\n",
    "\n",
    "            return df\n",
    "\n",
    "        df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n",
    "\n",
    "        df_events = df_events.drop(columns=['timeStamp','timestamp','timestamp_new'])\n",
    "        \n",
    "        # rename some columns\n",
    "        df_events = df_events.rename(columns=\n",
    "            {\n",
    "                'periodId':'current_phase',\n",
    "                'typeId':'event_type_id',\n",
    "                'timeMin':'period_minute',\n",
    "                'timeSec':'period_second'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return df_events\n",
    "\n",
    "    path_events = os.path.join(os.path.join(os.path.dirname(current_directory),'data'),\"first_10_events\")\n",
    "    #print(path_events)\n",
    "\n",
    "    event_file = f'{game_id}.json'\n",
    "\n",
    "    df_events = load_event_data(\n",
    "        base_path=path_events,\n",
    "        file_name=event_file\n",
    "    )\n",
    "\n",
    "    # add event descriptions\n",
    "    df_events['event_description'] = df_events['event_type_id'].map(dict_event_names)\n",
    "\n",
    "    # make a copy of it for later usage\n",
    "    events_all = df_events.copy()\n",
    "\n",
    "    #display(df_events.head())\n",
    "    #print(df_events['event_description'].unique())\n",
    "\n",
    "\n",
    "    #           ------------------------------------------------------------        \n",
    "\n",
    "\n",
    "    # read in qualifier list\n",
    "    path_data = os.path.join(os.path.dirname(current_directory),'data')\n",
    "    qualifier_names = pd.read_csv(os.path.join(path_data,\"qualifier_names.csv\"))\n",
    "\n",
    "    # explode coverts each element in each list to a separate row\n",
    "    cols = ['id', 'qualifier']\n",
    "    qualifiers = events_all[cols].explode('qualifier')\n",
    "    #display(qualifiers.head())\n",
    "\n",
    "    #print(\"------------\")\n",
    "\n",
    "    qualifiers = qualifiers[qualifiers.qualifier.notna()].reset_index(drop=True)\n",
    "    #print(qualifiers.shape)\n",
    "    #print(\"------------\")\n",
    "    #display(qualifiers.head())\n",
    "    #print(\"------------\")\n",
    "\n",
    "    # save corresponding event ids for each qualifier\n",
    "    event_ids = qualifiers.id.tolist()\n",
    "\n",
    "    qualifiers = pd.json_normalize(qualifiers[qualifiers.qualifier.notna()]['qualifier'])\n",
    "    #print(qualifiers.shape)\n",
    "    #print(\"------------\")\n",
    "    #display(qualifiers.head())\n",
    "    #print(\"------------\")\n",
    "    print(df_events['contestantId'].unique())\n",
    "    qualifiers['event_id'] = event_ids\n",
    "    #display(qualifiers.head())\n",
    "    print(\"------------\")\n",
    "    qualifiers = qualifiers.merge(qualifier_names, how='left', on='qualifierId')\n",
    "    #display(qualifiers.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
