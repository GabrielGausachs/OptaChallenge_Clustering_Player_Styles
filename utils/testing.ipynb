{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provant de llegir i entendre els datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracking data can be combined with event data with timeelapsed and current_phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The tracking data\n",
    "The tracking data contains the following columns:\n",
    "\n",
    "+ 'current_phase': the current period\n",
    "+ 'timeelapsed': the time in seconds of the current period \n",
    "+ 'team_id_opta': Opta team id\n",
    "+ 'player_id': Opta player id\n",
    "+ 'jersey_no': jersey number of the player\n",
    "+ 'pos_x': x-coordinate on the pitch; pitch coordinates in [-52.5, 52.5]\n",
    "+ 'pos_y': y-coordinate on the pitch; pitch coordinates in [-34, 34]\n",
    "+ 'frame_count': unique identifier for each frame\n",
    "+ 'team_id': inidicates home(=1)/away(=2); team_id 4 is the ball\n",
    "+ 'speed': speed\n",
    "+ 'acc': acceleration\n",
    "+ 'speed_x': speed regarding x-axis\n",
    "+ 'speed_y': speed regarding y-axis\n",
    "+ 'ball_x': x location of the ball\n",
    "+ 'ball_y': y location of the ball\n",
    "+ 'ball_speed': ball speed\n",
    "+ 'ball_acc': ball acceleration\n",
    "+ 'dop': direction of play of the team ('L'--> 'Left-to-Right; 'R' --> 'Right-to-Left'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The event data\n",
    "This event data is the Opta event data and contains the following columns:\n",
    "+ 'event_type_id': the Opta event type identifier; see 'event_description' for an explanation\n",
    "+ 'contestantId': id of the team\n",
    "+ 'playerId': id of the player\n",
    "+ 'current_phase': the current period\n",
    "+ 'timeelapsed': the time in seconds of the current period\n",
    "+ 'period_minute': the minute in which the game is currently\n",
    "+ 'period_second': the second of the minute in which the game is currently\n",
    "+ 'outcome': outcome of the event, 1=successful, 0=otherwise\n",
    "+ 'event_description': descriptions of 'event_type_id' (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegim dataset tracking i els noms de cada event amb el seu id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\OneDrive\\Escritorio\\SportsAnalyticsCourse\\OptaForum\\OptaChallenge_Clustering_Player_Styles\\data\\tracking_set_0\n"
     ]
    }
   ],
   "source": [
    "# load tracking data\n",
    "current_directory = os.getcwd()\n",
    "path_tracking = os.path.join(os.path.join(os.path.dirname(current_directory),'data'),\"tracking_set_0\")\n",
    "print(path_tracking)\n",
    "game_id = 1\n",
    "\n",
    "df_tracking = pd.read_parquet(f'{path_tracking}/{game_id}_tracking.parquet')\n",
    "\n",
    "#           ------------------------------------------------------------        \n",
    "\n",
    "# load events names\n",
    "path_event_csv = os.path.join(os.path.dirname(current_directory),'data')\n",
    "df_event_names = pd.read_csv(os.path.join(path_event_csv,'event_names.csv'))\n",
    "dict_event_names = df_event_names.set_index('event_type_id').to_dict()['event_description']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegim el dataset de event, ho relacionem amb el diccionari dels noms de cada event i afegim columna timeelapsed que es la que es relaciona amb tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriel\\OneDrive\\Escritorio\\SportsAnalyticsCourse\\OptaForum\\OptaChallenge_Clustering_Player_Styles\\data\\first_10_events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\AppData\\Local\\Temp\\ipykernel_16832\\4275543173.py:27: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n"
     ]
    }
   ],
   "source": [
    "# load event data\n",
    "def load_event_data(file_name, base_path):\n",
    "    # read in event file\n",
    "    with open(f'{base_path}/{file_name}') as f:\n",
    "        data=json.loads(f.read())\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    # transform data into pandas dataframe\n",
    "    df_events = pd.json_normalize(data['liveData']['event'])\n",
    "    \n",
    "    # preprocess event data and keep relevant information only\n",
    "\n",
    "    # add timeelapsed to each event\n",
    "    df_events['timestamp'] = pd.to_datetime(df_events.timeStamp).apply(lambda x: x.timestamp())\n",
    "\n",
    "    df_events = df_events.query('periodId in [1,2]')\n",
    "\n",
    "    def add_timeelapsed_to_events(df):\n",
    "        start_time = df.query('typeId==32')['timestamp'].iloc[0]\n",
    "        df['timestamp_new'] = np.int64((df['timestamp'] - start_time)*1000)\n",
    "\n",
    "        df['timeelapsed'] = df['timestamp_new'].apply(lambda x: (40 * round(x/40))/1000)\n",
    "\n",
    "        return df\n",
    "\n",
    "    df_events = df_events.groupby('periodId').apply(add_timeelapsed_to_events)\n",
    "\n",
    "    df_events = df_events.drop(columns=['timeStamp','timestamp','timestamp_new'])\n",
    "    \n",
    "    # rename some columns\n",
    "    df_events = df_events.rename(columns=\n",
    "        {\n",
    "            'periodId':'current_phase',\n",
    "            'typeId':'event_type_id',\n",
    "            'timeMin':'period_minute',\n",
    "            'timeSec':'period_second'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return df_events\n",
    "\n",
    "path_events = os.path.join(os.path.join(os.path.dirname(current_directory),'data'),\"first_10_events\")\n",
    "print(path_events)\n",
    "\n",
    "event_file = f'{game_id}.json'\n",
    "\n",
    "df_events = load_event_data(\n",
    "    base_path=path_events,\n",
    "    file_name=event_file\n",
    ")\n",
    "\n",
    "# add event descriptions\n",
    "df_events['event_description'] = df_events['event_type_id'].map(dict_event_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset event, hi ha una columna que es qualifier. Aquesta columna es un nested diccionary que si fem un merge amb el qualifier_names.csv podrem veure informació més detallada de l'event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fer:\n",
    "- Agafar un event i veure quina informació tinc amb els qualifiers. Provar-ho amb diferents events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
